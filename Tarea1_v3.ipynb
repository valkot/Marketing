{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06fc08ac",
   "metadata": {},
   "source": [
    "PARTE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7316dc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      categoria      GMROI  Markdown_Pct\n",
      "137                       Hogar  94.049948      6.983152\n",
      "229                   Relojería  86.077190      4.746089\n",
      "58                       Carnes  84.140954      5.391397\n",
      "151                 Informática  81.553854      6.693066\n",
      "196                     Muebles  81.403035      3.758732\n",
      "240                 Ropa Hombre  80.933400      5.923863\n",
      "86                     Deportes  80.854814      9.166626\n",
      "20                   Automotriz  79.969620      5.207047\n",
      "216  Pequeños Electrodomésticos  79.892662      4.808126\n",
      "180                     Lácteos  79.524157      6.643881\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. CARGA DE DATOS\n",
    "ventas = pd.read_csv('transacciones_ventas.csv')\n",
    "inventario = pd.read_csv('inventario_diario.csv')\n",
    "maestro = pd.read_csv('maestro_productos.csv')\n",
    "\n",
    "def clean_numeric(series):\n",
    "    # Elimina ruido (símbolos, espacios) y convierte a numérico\n",
    "    if series.dtype == 'O':\n",
    "        return pd.to_numeric(series.astype(str).str.replace(r'[^\\d.-]', '', regex=True), errors='coerce')\n",
    "    return pd.to_numeric(series, errors='coerce')\n",
    "\n",
    "# 2. LIMPIEZA DE CATEGORÍAS Y TIPOS\n",
    "for df in [ventas, inventario, maestro]:\n",
    "    if 'categoria' in df.columns:\n",
    "        df['categoria'] = df['categoria'].astype(str).str.strip().str.title()\n",
    "\n",
    "# Conversión numérica de columnas críticas\n",
    "cols_ventas = ['unidades_vendidas', 'precio_unitario_venta', 'precio_lista_original', 'costo_unitario']\n",
    "for col in cols_ventas:\n",
    "    ventas[col] = clean_numeric(ventas[col])\n",
    "\n",
    "inventario['valor_inventario_costo'] = clean_numeric(inventario['valor_inventario_costo'])\n",
    "maestro['costo_unitario'] = clean_numeric(maestro['costo_unitario'])\n",
    "maestro['precio_lista'] = clean_numeric(maestro['precio_lista'])\n",
    "\n",
    "# 3. INTEGRACIÓN CON MAESTRO DE PRODUCTOS\n",
    "# Usamos el maestro para rellenar costos o precios de lista faltantes en ventas\n",
    "ventas_full = ventas.merge(maestro[['product_id', 'costo_unitario', 'precio_lista']], \n",
    "                           on='product_id', how='left', suffixes=('_v', '_m'))\n",
    "\n",
    "# Lógica de fallback\n",
    "ventas_full['costo_final'] = ventas_full['costo_unitario_v'].fillna(ventas_full['costo_unitario_m'])\n",
    "ventas_full['precio_lista_final'] = ventas_full['precio_lista_original'].fillna(ventas_full['precio_lista'])\n",
    "\n",
    "# 4. CÁLCULO DE MÉTRICAS\n",
    "ventas_full['utilidad_bruta'] = ventas_full['unidades_vendidas'] * (ventas_full['precio_unitario_venta'] - ventas_full['costo_final'])\n",
    "ventas_full['ingreso_real'] = ventas_full['unidades_vendidas'] * ventas_full['precio_unitario_venta']\n",
    "ventas_full['ingreso_potencial'] = ventas_full['unidades_vendidas'] * ventas_full['precio_lista_final']\n",
    "\n",
    "# Agrupación por categoría (filtrando valores nulos de categoría)\n",
    "ventas_full = ventas_full[ventas_full['categoria'] != 'Nan']\n",
    "cat_stats = ventas_full.groupby('categoria').agg({\n",
    "    'utilidad_bruta': 'sum',\n",
    "    'ingreso_real': 'sum',\n",
    "    'ingreso_potencial': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Inventario promedio a costo\n",
    "cat_inv = inventario[inventario['categoria'] != 'Nan'].groupby('categoria')['valor_inventario_costo'].mean().reset_index()\n",
    "cat_inv.columns = ['categoria', 'inv_promedio_costo']\n",
    "\n",
    "# 5. RESULTADOS FINALES (GMROI y Markdown)\n",
    "df_final = cat_stats.merge(cat_inv, on='categoria')\n",
    "df_final['GMROI'] = df_final['utilidad_bruta'] / df_final['inv_promedio_costo']\n",
    "df_final['Markdown_Pct'] = (1 - (df_final['ingreso_real'] / df_final['ingreso_potencial'])) * 100\n",
    "\n",
    "print(df_final[['categoria', 'GMROI', 'Markdown_Pct']].sort_values(by='GMROI', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e618a9e4",
   "metadata": {},
   "source": [
    "PARTE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862eb8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extrayendo CASA en Huechuraba ---\n",
      "Procesando página 1...\n",
      "Procesando página 2...\n",
      "Procesando página 3...\n",
      "Procesando página 4...\n",
      "Procesando página 5...\n",
      "Procesando página 6...\n",
      "Procesando página 7...\n",
      "Procesando página 8...\n",
      "Procesando página 9...\n",
      "Procesando página 10...\n",
      "Procesando página 11...\n",
      "Procesando página 12...\n",
      "Procesando página 13...\n",
      "Procesando página 14...\n",
      "Procesando página 15...\n",
      "\n",
      "--- Extrayendo DEPARTAMENTO en Huechuraba ---\n",
      "Procesando página 1...\n",
      "Procesando página 2...\n",
      "Procesando página 3...\n",
      "Procesando página 4...\n",
      "Procesando página 5...\n",
      "Procesando página 6...\n",
      "Procesando página 7...\n",
      "Procesando página 8...\n",
      "Procesando página 9...\n",
      "Procesando página 10...\n",
      "Procesando página 11...\n",
      "\n",
      "=================================================================\n",
      "Métrica                             | Casas        | Deptos      \n",
      "-----------------------------------------------------------------\n",
      "Propiedades filtradas (#)           | 670          | 489         \n",
      "Mediana precio (UF)                 | 8570         | 5750        \n",
      "Promedio precio (UF)                | 9776         | 6075        \n",
      "Precio por m2 (UF/m2)               | 62.43        | 66.06       \n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import statistics\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def realizar_tarea_final():\n",
    "    async def scrape_tipo(tipo):\n",
    "        print(f\"\\n--- Extrayendo {tipo.upper()} en Huechuraba ---\")\n",
    "        results = []\n",
    "        async with async_playwright() as p:\n",
    "            browser = await p.chromium.launch(headless=False)\n",
    "            page = await browser.new_page()\n",
    "            url = f\"https://www.portalinmobiliario.cl/venta/{tipo}/huechuraba-metropolitana\"\n",
    "            \n",
    "            try:\n",
    "                await page.goto(url, wait_until=\"domcontentloaded\", timeout=60000)\n",
    "                pagina = 1\n",
    "                while True:\n",
    "                    print(f\"Procesando página {pagina}...\")\n",
    "                    await asyncio.sleep(2)\n",
    "                    await page.mouse.wheel(0, 3000)\n",
    "                    await asyncio.sleep(1)\n",
    "\n",
    "                    items = await page.query_selector_all(\".ui-search-result__wrapper\")\n",
    "                    for item in items:\n",
    "                        try:\n",
    "                            # 1. Obtener Precio\n",
    "                            p_elem = await item.query_selector(\".andes-money-amount__fraction\")\n",
    "                            # 2. Obtener Símbolo de moneda (UF vs $)\n",
    "                            currency_elem = await item.query_selector(\".andes-money-amount__currency-symbol\")\n",
    "                            currency = await currency_elem.inner_text() if currency_elem else \"\"\n",
    "                            \n",
    "                            card_text = await item.inner_text()\n",
    "                            m2_val = None\n",
    "                            if \"m²\" in card_text:\n",
    "                                parts = card_text.split()\n",
    "                                for i, part in enumerate(parts):\n",
    "                                    if \"m²\" in part and i > 0:\n",
    "                                        m2_val = float(parts[i-1].replace('.', '').replace(',', '.'))\n",
    "                                        break\n",
    "                            \n",
    "                            if p_elem and m2_val and \"UF\" in currency:\n",
    "                                price = float((await p_elem.inner_text()).replace('.', ''))\n",
    "                                # Filtro de seguridad para evitar datos erróneos\n",
    "                                if 1000 < price < 100000: \n",
    "                                    results.append({\"p\": price, \"m\": m2_val})\n",
    "                        except: continue\n",
    "\n",
    "                    # Lógica de paginación, para el navbar\n",
    "                    next_btn = await page.query_selector('a[title=\"Siguiente\"]')\n",
    "                    if next_btn and await next_btn.is_visible():\n",
    "                        await next_btn.click()\n",
    "                        pagina += 1\n",
    "                        await page.wait_for_load_state(\"domcontentloaded\")\n",
    "                    else:\n",
    "                        break # Salir del bucle si no hay más páginas\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Fin de navegación: {e}\")\n",
    "            finally:\n",
    "                await browser.close()\n",
    "        return results\n",
    "\n",
    "    c_data = await scrape_tipo(\"casa\")\n",
    "    d_data = await scrape_tipo(\"departamento\")\n",
    "\n",
    "    def get_stats(lista):\n",
    "        if not lista: return [0, 0, 0, 0]\n",
    "        precios = [x['p'] for x in lista]\n",
    "        uf_m2 = [x['p']/x['m'] for x in lista if x['m'] > 0]\n",
    "        return [len(lista), statistics.median(precios), statistics.mean(precios), statistics.mean(uf_m2)]\n",
    "\n",
    "    c, d = get_stats(c_data), get_stats(d_data)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    print(f\"{'Métrica':<35} | {'Casas':<12} | {'Deptos':<12}\")\n",
    "    print(\"-\" * 65)\n",
    "    print(f\"{'Propiedades filtradas (#)':<35} | {c[0]:<12.0f} | {d[0]:<12.0f}\")\n",
    "    print(f\"{'Mediana precio (UF)':<35} | {c[1]:<12.0f} | {d[1]:<12.0f}\")\n",
    "    print(f\"{'Promedio precio (UF)':<35} | {c[2]:<12.0f} | {d[2]:<12.0f}\")\n",
    "    print(f\"{'Precio por m2 (UF/m2)':<35} | {c[3]:<12.2f} | {d[3]:<12.2f}\")\n",
    "    print(\"=\"*65)\n",
    "\n",
    "await realizar_tarea_final()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d26eaa1",
   "metadata": {},
   "source": [
    "TERCERA PARTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6570838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Reporte de Clasificación ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94     30034\n",
      "           1       0.83      0.31      0.46      5066\n",
      "\n",
      "    accuracy                           0.89     35100\n",
      "   macro avg       0.86      0.65      0.70     35100\n",
      "weighted avg       0.89      0.89      0.87     35100\n",
      "\n",
      "\n",
      "=== Importancia de las Variables ===\n",
      "       Variable  Importancia\n",
      "3  satisfaccion     0.722663\n",
      "2       soporte     0.169835\n",
      "0    antiguedad     0.090807\n",
      "1         gasto     0.016694\n",
      "\n",
      "=== Tabla de Análisis de Lift ===\n",
      "       Clientes_Total  Churns_Reales  Tasa_Respuesta_Decil      Lift  \\\n",
      "Decil                                                                  \n",
      "1                3510           2385              0.679487  4.707856   \n",
      "2                3510           1505              0.428775  2.970786   \n",
      "3                3510            577              0.164387  1.138966   \n",
      "4                3510            236              0.067236  0.465851   \n",
      "5                3510             59              0.016809  0.116463   \n",
      "6                3510             58              0.016524  0.114489   \n",
      "7                3510             61              0.017379  0.120411   \n",
      "8                3510             60              0.017094  0.118437   \n",
      "9                3510             70              0.019943  0.138176   \n",
      "10               3510             55              0.015670  0.108567   \n",
      "\n",
      "       %_Captura_Acumulada  \n",
      "Decil                       \n",
      "1                47.078563  \n",
      "2                76.786419  \n",
      "3                88.176076  \n",
      "4                92.834583  \n",
      "5                93.999210  \n",
      "6                95.144098  \n",
      "7                96.348204  \n",
      "8                97.532570  \n",
      "9                98.914331  \n",
      "10              100.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1. Cargar datos\n",
    "df = pd.read_csv('data_churn.csv')\n",
    "\n",
    "# 2. Definir Features (X) y Target (y)\n",
    "X = df.drop('churn_real', axis=1)\n",
    "y = df['churn_real']\n",
    "\n",
    "# 3. Dividir en conjunto de entrenamiento (70%) y prueba (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 4. Entrenar el modelo\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "y_probs = model.predict_proba(X_test)[:, 1] # Probabilidad de Churn (clase 1)\n",
    "\n",
    "# Mostrar métricas básicas\n",
    "print(\"=== Reporte de Clasificación ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Importancia de variables (extra útil)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Variable': X.columns,\n",
    "    'Importancia': model.feature_importances_\n",
    "}).sort_values('Importancia', ascending=False)\n",
    "\n",
    "print(\"\\n=== Importancia de las Variables ===\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Crear un DataFrame con los resultados del test\n",
    "lift_df = pd.DataFrame({'Actual': y_test, 'Probabilidad_Churn': y_probs})\n",
    "\n",
    "# Ordenar por probabilidad de mayor a menor\n",
    "lift_df = lift_df.sort_values(by='Probabilidad_Churn', ascending=False)\n",
    "\n",
    "# Dividir en 10 deciles (qcut intenta dividir en grupos de igual tamaño)\n",
    "# Usamos rank method='first' para romper empates y asegurar 10 grupos exactos si hay probs repetidas\n",
    "lift_df['Decil'] = pd.qcut(lift_df['Probabilidad_Churn'].rank(method='first'), 10, labels=False)\n",
    "lift_df['Decil'] = 9 - lift_df['Decil'] + 1 # Invertir para que 1 sea el decil con mayor probabilidad\n",
    "\n",
    "# Calcular métricas por decil\n",
    "resumen_lift = lift_df.groupby('Decil').agg(\n",
    "    Clientes_Total=('Actual', 'count'),\n",
    "    Churns_Reales=('Actual', 'sum')\n",
    ")\n",
    "\n",
    "# Calcular Tasa de Churn por decil y Lift\n",
    "tasa_global_churn = lift_df['Actual'].mean() # La tasa promedio de toda la base test\n",
    "resumen_lift['Tasa_Respuesta_Decil'] = resumen_lift['Churns_Reales'] / resumen_lift['Clientes_Total']\n",
    "resumen_lift['Lift'] = resumen_lift['Tasa_Respuesta_Decil'] / tasa_global_churn\n",
    "\n",
    "# Calcular Lift Acumulado\n",
    "resumen_lift['Churn_Acumulado'] = resumen_lift['Churns_Reales'].cumsum()\n",
    "resumen_lift['Total_Churns_En_Test'] = lift_df['Actual'].sum()\n",
    "resumen_lift['%_Captura_Acumulada'] = (resumen_lift['Churn_Acumulado'] / resumen_lift['Total_Churns_En_Test']) * 100\n",
    "\n",
    "print(\"\\n=== Tabla de Análisis de Lift ===\")\n",
    "print(resumen_lift[['Clientes_Total', 'Churns_Reales', 'Tasa_Respuesta_Decil', 'Lift', '%_Captura_Acumulada']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
